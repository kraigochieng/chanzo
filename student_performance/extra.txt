def stream_graph_updates(user_input: str):
    with SqliteSaver.from_conn_string(CHECKPOINTS_DB) as checkpointer:
        graph = graph_builder.compile(checkpointer=checkpointer, store=in_memory_store)

        graph_input = {"messages": [HumanMessage(user_input)], "text": user_input}
        for event in graph.stream(input=graph_input, config=config):
            for key, value in event.items():
                if key == "classification_node":
                    console = Console()
                    print(key)
                    print("-" * 50)
                    # md = Markdown(value["classification"])
                    # console.print(md)
                    print(value)
                    print("=" * 50)
                else:
                    print(key)
                    print("-" * 50)
                    print(value)
                    print("=" * 50)
















# # Define Nodes
# def summarisation_node(state: State):
#     summary = state.get("summary", "")

#     if summary:
#         summary_message = (
#             f"This is a summary of the conversation to date: {summary}\n\n"
#             "Extend the summary by taking into account the new messages above:"
#         )

#     else:
#         summary_message = "Create a summary of the conversation above:"

#     # Add previous messages togther with summary message
#     messages = state["messages"] + [HumanMessage(content=summary_message)]
#     response = llm.invoke(messages)

#     # Delete all but the 2 most recent messages
#     delete_messages = [RemoveMessage(id=m.id) for m in state["messages"][:-2]]
#     return {"summary": response.content, "messages": delete_messages}


# def classification_node(state: State):
#     prompt = PromptTemplate(
#         input_variables=["text"],
#         template="""
#     Classify the folowing text into one of the categories:
#     1. Grade Probability
#     2. Strength and weakness of student
#     3. Career recommendation for student
#     4. Other

#     Text: {text}

#     Category:
#     """,
#     )

#     message = HumanMessage(content=prompt.format(text=state["text"]))

#     llm_with_structured_output = llm.with_structured_output(Classification)

#     # classification = llm.invoke([message]).content.strip()

#     classification: Classification = llm_with_structured_output.invoke([message])

#     return {"classification": classification.classification.value}