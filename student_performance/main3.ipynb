{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "# from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "from pprint import pprint\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stream</th>\n",
       "      <th>Student Name</th>\n",
       "      <th>Subject Category</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Subject Strand</th>\n",
       "      <th>Term</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Grade Numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Holly</td>\n",
       "      <td>Languages</td>\n",
       "      <td>English</td>\n",
       "      <td>English Reading</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Holly</td>\n",
       "      <td>Languages</td>\n",
       "      <td>English</td>\n",
       "      <td>English Reading</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Holly</td>\n",
       "      <td>Languages</td>\n",
       "      <td>English</td>\n",
       "      <td>English Reading</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Holly</td>\n",
       "      <td>Languages</td>\n",
       "      <td>English</td>\n",
       "      <td>English Writing</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Holly</td>\n",
       "      <td>Languages</td>\n",
       "      <td>English</td>\n",
       "      <td>English Writing</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stream Student Name Subject Category  Subject   Subject Strand  Term Grade  \\\n",
       "0  Yellow        Holly        Languages  English  English Reading     1     B   \n",
       "1  Yellow        Holly        Languages  English  English Reading     2     A   \n",
       "2  Yellow        Holly        Languages  English  English Reading     3     B   \n",
       "3  Yellow        Holly        Languages  English  English Writing     1     A   \n",
       "4  Yellow        Holly        Languages  English  English Writing     2     B   \n",
       "\n",
       "   Grade Numeric  \n",
       "0              4  \n",
       "1              5  \n",
       "2              4  \n",
       "3              5  \n",
       "4              4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data3.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "streams = list(df[\"Stream\"].unique())\n",
    "student_names = list(df[\"Student Name\"].unique())\n",
    "subject_categories = list(df[\"Subject Category\"].unique())\n",
    "subjects = list(df[\"Subject\"].unique())\n",
    "subject_strands = list(df[\"Subject Strand\"].unique())\n",
    "terms = list(df[\"Term\"].unique())\n",
    "grades = list(df[\"Grade\"].unique())\n",
    "\n",
    "\n",
    "subject_strand_to_subject = {\n",
    "    \"English Reading\": \"English\",\n",
    "    \"English Writing\": \"English\",\n",
    "    \"Vocabulary\": \"Spanish\",\n",
    "    \"Spanish Grammar\": \"Spanish\",\n",
    "    \"Algebra\": \"Math\",\n",
    "    \"Geometry\": \"Math\",\n",
    "    \"Mechanics\": \"Physics\",\n",
    "    \"Thermodynamics\": \"Physics\",\n",
    "    \"Physical Geography\": \"Geography\",\n",
    "    \"Human Geography\": \"Geography\",\n",
    "    \"Ancient History\": \"History\",\n",
    "    \"Medieval History\": \"History\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get unique subject strands\n",
    "# subject_strands = df[\"Subject Strand\"].unique()\n",
    "# num_strands = len(subject_strands)\n",
    "\n",
    "# # Create a FacetGrid for multiple subject strands\n",
    "# g = sns.catplot(\n",
    "#     data=df,\n",
    "#     x=\"Grade\",\n",
    "#     hue=\"Stream\",\n",
    "#     col=\"Subject Strand\",\n",
    "#     kind=\"count\",\n",
    "#     col_wrap=3,\n",
    "#     height=4,\n",
    "#     aspect=1.2,\n",
    "# )\n",
    "\n",
    "# g.set_titles(\"Proportions for Subject: {col_name}\")\n",
    "# g.set_axis_labels(\"Grade\", \"Count\")\n",
    "# g.legend.set_title(\"Stream\")\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grade to Numeric Ranking\n",
    "- A - 5\n",
    "- B - 4\n",
    "- C - 3\n",
    "- D - 2\n",
    "- E - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative Rank of Grade of a Student as per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stream</th>\n",
       "      <th>Student Name</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Subject Strand</th>\n",
       "      <th>Grade Numeric</th>\n",
       "      <th>Percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Holly</td>\n",
       "      <td>English</td>\n",
       "      <td>English Reading</td>\n",
       "      <td>4.3</td>\n",
       "      <td>77.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Holly</td>\n",
       "      <td>English</td>\n",
       "      <td>English Writing</td>\n",
       "      <td>4.3</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Holly</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Vocabulary</td>\n",
       "      <td>4.7</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Holly</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Spanish Grammar</td>\n",
       "      <td>4.3</td>\n",
       "      <td>66.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Holly</td>\n",
       "      <td>Math</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>4.7</td>\n",
       "      <td>81.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Holly</td>\n",
       "      <td>Math</td>\n",
       "      <td>Geometry</td>\n",
       "      <td>4.7</td>\n",
       "      <td>77.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Holly</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Mechanics</td>\n",
       "      <td>4.3</td>\n",
       "      <td>77.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Holly</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Thermodynamics</td>\n",
       "      <td>3.7</td>\n",
       "      <td>51.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Holly</td>\n",
       "      <td>Geography</td>\n",
       "      <td>Physical Geography</td>\n",
       "      <td>4.0</td>\n",
       "      <td>76.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Holly</td>\n",
       "      <td>Geography</td>\n",
       "      <td>Human Geography</td>\n",
       "      <td>5.0</td>\n",
       "      <td>86.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Holly</td>\n",
       "      <td>History</td>\n",
       "      <td>Ancient History</td>\n",
       "      <td>3.7</td>\n",
       "      <td>46.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Holly</td>\n",
       "      <td>History</td>\n",
       "      <td>Medieval History</td>\n",
       "      <td>4.0</td>\n",
       "      <td>68.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Jon</td>\n",
       "      <td>English</td>\n",
       "      <td>English Reading</td>\n",
       "      <td>4.7</td>\n",
       "      <td>77.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Jon</td>\n",
       "      <td>English</td>\n",
       "      <td>English Writing</td>\n",
       "      <td>4.0</td>\n",
       "      <td>71.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Jon</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Vocabulary</td>\n",
       "      <td>5.0</td>\n",
       "      <td>94.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Jon</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Spanish Grammar</td>\n",
       "      <td>4.7</td>\n",
       "      <td>66.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Jon</td>\n",
       "      <td>Math</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>4.7</td>\n",
       "      <td>81.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Jon</td>\n",
       "      <td>Math</td>\n",
       "      <td>Geometry</td>\n",
       "      <td>4.3</td>\n",
       "      <td>77.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Jon</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Mechanics</td>\n",
       "      <td>4.7</td>\n",
       "      <td>77.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Jon</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Thermodynamics</td>\n",
       "      <td>5.0</td>\n",
       "      <td>92.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Jon</td>\n",
       "      <td>Geography</td>\n",
       "      <td>Physical Geography</td>\n",
       "      <td>4.7</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Jon</td>\n",
       "      <td>Geography</td>\n",
       "      <td>Human Geography</td>\n",
       "      <td>5.0</td>\n",
       "      <td>86.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Jon</td>\n",
       "      <td>History</td>\n",
       "      <td>Ancient History</td>\n",
       "      <td>5.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>Jon</td>\n",
       "      <td>History</td>\n",
       "      <td>Medieval History</td>\n",
       "      <td>4.3</td>\n",
       "      <td>83.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Stream Student Name    Subject      Subject Strand  Grade Numeric  \\\n",
       "0   Yellow        Holly    English     English Reading            4.3   \n",
       "1   Yellow        Holly    English     English Writing            4.3   \n",
       "2   Yellow        Holly    Spanish          Vocabulary            4.7   \n",
       "3   Yellow        Holly    Spanish     Spanish Grammar            4.3   \n",
       "4   Yellow        Holly       Math             Algebra            4.7   \n",
       "5   Yellow        Holly       Math            Geometry            4.7   \n",
       "6   Yellow        Holly    Physics           Mechanics            4.3   \n",
       "7   Yellow        Holly    Physics      Thermodynamics            3.7   \n",
       "8   Yellow        Holly  Geography  Physical Geography            4.0   \n",
       "9   Yellow        Holly  Geography     Human Geography            5.0   \n",
       "10  Yellow        Holly    History     Ancient History            3.7   \n",
       "11  Yellow        Holly    History    Medieval History            4.0   \n",
       "12  Yellow          Jon    English     English Reading            4.7   \n",
       "13  Yellow          Jon    English     English Writing            4.0   \n",
       "14  Yellow          Jon    Spanish          Vocabulary            5.0   \n",
       "15  Yellow          Jon    Spanish     Spanish Grammar            4.7   \n",
       "16  Yellow          Jon       Math             Algebra            4.7   \n",
       "17  Yellow          Jon       Math            Geometry            4.3   \n",
       "18  Yellow          Jon    Physics           Mechanics            4.7   \n",
       "19  Yellow          Jon    Physics      Thermodynamics            5.0   \n",
       "20  Yellow          Jon  Geography  Physical Geography            4.7   \n",
       "21  Yellow          Jon  Geography     Human Geography            5.0   \n",
       "22  Yellow          Jon    History     Ancient History            5.0   \n",
       "23  Yellow          Jon    History    Medieval History            4.3   \n",
       "\n",
       "    Percentile  \n",
       "0         77.8  \n",
       "1         87.0  \n",
       "2         87.0  \n",
       "3         66.7  \n",
       "4         81.5  \n",
       "5         77.8  \n",
       "6         77.8  \n",
       "7         51.9  \n",
       "8         76.9  \n",
       "9         86.1  \n",
       "10        46.3  \n",
       "11        68.5  \n",
       "12        77.8  \n",
       "13        71.3  \n",
       "14        94.4  \n",
       "15        66.7  \n",
       "16        81.5  \n",
       "17        77.8  \n",
       "18        77.8  \n",
       "19        92.6  \n",
       "20        87.0  \n",
       "21        86.1  \n",
       "22        88.0  \n",
       "23        83.3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stream</th>\n",
       "      <th>Student Name</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Subject Strand</th>\n",
       "      <th>Grade Numeric</th>\n",
       "      <th>Percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Mallory</td>\n",
       "      <td>English</td>\n",
       "      <td>English Reading</td>\n",
       "      <td>1.3</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Mallory</td>\n",
       "      <td>English</td>\n",
       "      <td>English Writing</td>\n",
       "      <td>1.7</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Mallory</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Vocabulary</td>\n",
       "      <td>3.3</td>\n",
       "      <td>75.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Mallory</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Spanish Grammar</td>\n",
       "      <td>1.7</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Mallory</td>\n",
       "      <td>Math</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>2.3</td>\n",
       "      <td>55.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Mallory</td>\n",
       "      <td>Math</td>\n",
       "      <td>Geometry</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Mallory</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Mechanics</td>\n",
       "      <td>2.7</td>\n",
       "      <td>46.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Mallory</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Thermodynamics</td>\n",
       "      <td>2.3</td>\n",
       "      <td>48.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Mallory</td>\n",
       "      <td>Geography</td>\n",
       "      <td>Physical Geography</td>\n",
       "      <td>4.3</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Mallory</td>\n",
       "      <td>Geography</td>\n",
       "      <td>Human Geography</td>\n",
       "      <td>2.3</td>\n",
       "      <td>55.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Mallory</td>\n",
       "      <td>History</td>\n",
       "      <td>Ancient History</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Mallory</td>\n",
       "      <td>History</td>\n",
       "      <td>Medieval History</td>\n",
       "      <td>2.7</td>\n",
       "      <td>51.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Samantha</td>\n",
       "      <td>English</td>\n",
       "      <td>English Reading</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Samantha</td>\n",
       "      <td>English</td>\n",
       "      <td>English Writing</td>\n",
       "      <td>1.7</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Samantha</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Vocabulary</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Samantha</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Spanish Grammar</td>\n",
       "      <td>2.7</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Samantha</td>\n",
       "      <td>Math</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Samantha</td>\n",
       "      <td>Math</td>\n",
       "      <td>Geometry</td>\n",
       "      <td>1.3</td>\n",
       "      <td>27.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Samantha</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Mechanics</td>\n",
       "      <td>3.3</td>\n",
       "      <td>81.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Samantha</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Thermodynamics</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Samantha</td>\n",
       "      <td>Geography</td>\n",
       "      <td>Physical Geography</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Samantha</td>\n",
       "      <td>Geography</td>\n",
       "      <td>Human Geography</td>\n",
       "      <td>1.7</td>\n",
       "      <td>25.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Samantha</td>\n",
       "      <td>History</td>\n",
       "      <td>Ancient History</td>\n",
       "      <td>1.3</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Samantha</td>\n",
       "      <td>History</td>\n",
       "      <td>Medieval History</td>\n",
       "      <td>2.7</td>\n",
       "      <td>51.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Stream Student Name    Subject      Subject Strand  Grade Numeric  \\\n",
       "396   Blue      Mallory    English     English Reading            1.3   \n",
       "397   Blue      Mallory    English     English Writing            1.7   \n",
       "398   Blue      Mallory    Spanish          Vocabulary            3.3   \n",
       "399   Blue      Mallory    Spanish     Spanish Grammar            1.7   \n",
       "400   Blue      Mallory       Math             Algebra            2.3   \n",
       "401   Blue      Mallory       Math            Geometry            4.0   \n",
       "402   Blue      Mallory    Physics           Mechanics            2.7   \n",
       "403   Blue      Mallory    Physics      Thermodynamics            2.3   \n",
       "404   Blue      Mallory  Geography  Physical Geography            4.3   \n",
       "405   Blue      Mallory  Geography     Human Geography            2.3   \n",
       "406   Blue      Mallory    History     Ancient History            2.0   \n",
       "407   Blue      Mallory    History    Medieval History            2.7   \n",
       "408   Blue     Samantha    English     English Reading            2.0   \n",
       "409   Blue     Samantha    English     English Writing            1.7   \n",
       "410   Blue     Samantha    Spanish          Vocabulary            3.0   \n",
       "411   Blue     Samantha    Spanish     Spanish Grammar            2.7   \n",
       "412   Blue     Samantha       Math             Algebra            2.0   \n",
       "413   Blue     Samantha       Math            Geometry            1.3   \n",
       "414   Blue     Samantha    Physics           Mechanics            3.3   \n",
       "415   Blue     Samantha    Physics      Thermodynamics            2.0   \n",
       "416   Blue     Samantha  Geography  Physical Geography            2.0   \n",
       "417   Blue     Samantha  Geography     Human Geography            1.7   \n",
       "418   Blue     Samantha    History     Ancient History            1.3   \n",
       "419   Blue     Samantha    History    Medieval History            2.7   \n",
       "\n",
       "     Percentile  \n",
       "396        33.3  \n",
       "397        20.4  \n",
       "398        75.9  \n",
       "399        33.3  \n",
       "400        55.6  \n",
       "401        84.3  \n",
       "402        46.3  \n",
       "403        48.1  \n",
       "404        87.0  \n",
       "405        55.6  \n",
       "406        50.0  \n",
       "407        51.9  \n",
       "408        46.3  \n",
       "409        20.4  \n",
       "410        63.9  \n",
       "411        63.0  \n",
       "412        44.4  \n",
       "413        27.8  \n",
       "414        81.5  \n",
       "415        42.6  \n",
       "416        36.1  \n",
       "417        25.9  \n",
       "418        33.3  \n",
       "419        51.9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for stream in streams:\n",
    "    # Get specific stream\n",
    "    stream_df = df[df[\"Stream\"] == stream]\n",
    "\n",
    "    # Get details of this stream\n",
    "    student_names = list(stream_df[\"Student Name\"].unique())\n",
    "    subject_strands = list(stream_df[\"Subject Strand\"].unique())\n",
    "\n",
    "    # For each student look at how well they did in each subject\n",
    "    for student_name in student_names:\n",
    "        student_df = stream_df[stream_df[\"Student Name\"] == student_name]\n",
    "\n",
    "        for subject_strand in subject_strands:\n",
    "            subject = subject_strand_to_subject[subject_strand]\n",
    "            # Get Mean and Median for strean in specific strand\n",
    "\n",
    "            stream_subject_strand_df = stream_df[\n",
    "                stream_df[\"Subject Strand\"] == subject_strand\n",
    "            ]\n",
    "\n",
    "            stream_subject_strand_mean = stream_subject_strand_df[\n",
    "                \"Grade Numeric\"\n",
    "            ].mean().round(1)\n",
    "\n",
    "            # stream_subject_strand_median = stream_subject_strand_df[\n",
    "            #     \"Grade Numeric\"\n",
    "            # ].median()\n",
    "\n",
    "            stream_subject_strand_std = stream_subject_strand_df[\n",
    "                \"Grade Numeric\"\n",
    "            ].std()\n",
    "\n",
    "            # Get stream mean in a particular strand\n",
    "            student_subject_strand_df = student_df[\n",
    "                student_df[\"Subject Strand\"] == subject_strand\n",
    "            ]\n",
    "\n",
    "            student_subject_strand_mean = student_subject_strand_df[\n",
    "                \"Grade Numeric\"\n",
    "            ].mean().round(1)\n",
    "\n",
    "            # student_z_score = (\n",
    "            #     (student_subject_strand_mean - stream_subject_strand_mean)\n",
    "            #     / stream_subject_strand_std\n",
    "            #     # if stream_subject_strand_std != 0\n",
    "            #     # else 0\n",
    "            # )\n",
    "\n",
    "            student_percentile = scipy.stats.percentileofscore(\n",
    "                stream_subject_strand_df[\"Grade Numeric\"],\n",
    "                student_subject_strand_mean,\n",
    "            ).round(1)\n",
    "\n",
    "            data.append(\n",
    "                [\n",
    "                    stream,\n",
    "                    student_name,\n",
    "                    subject,\n",
    "                    subject_strand,\n",
    "                    student_subject_strand_mean,\n",
    "                    student_percentile,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "\n",
    "subject_strand_percentile_df = pd.DataFrame(\n",
    "    data,\n",
    "    columns=[\n",
    "        \"Stream\",\n",
    "        \"Student Name\",\n",
    "        \"Subject\",\n",
    "        \"Subject Strand\",\n",
    "        \"Grade Numeric\",\n",
    "        \"Percentile\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "display(subject_strand_percentile_df.head(24))\n",
    "display(subject_strand_percentile_df.tail(24))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some students, having around 3 makes them in the middle of their class wo in th 75th percentile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LLM for getting strengths and weaknesses of student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 63\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# llm_with_structured_output = llm.with_structured_output(RecommendationList)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     29\u001b[0m     SystemMessage(\n\u001b[1;32m     30\u001b[0m         content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m     ),\n\u001b[1;32m     61\u001b[0m ]\n\u001b[0;32m---> 63\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# output = llm_with_structured_output.invoke(messages)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/data_science/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:307\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    303\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    304\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    306\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 307\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    317\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/miniconda3/envs/data_science/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:843\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    836\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    837\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    841\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    842\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 843\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/data_science/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:683\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    681\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    682\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 683\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniconda3/envs/data_science/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:908\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 908\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    911\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    912\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/data_science/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:815\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    813\u001b[0m payload\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 815\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mBadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    817\u001b[0m     _handle_openai_bad_request(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/data_science/lib/python3.10/site-packages/openai/resources/beta/chat/completions.py:158\u001b[0m, in \u001b[0;36mCompletions.parse\u001b[0;34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparser\u001b[39m(raw_completion: ChatCompletion) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ParsedChatCompletion[ResponseFormatT]:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[1;32m    153\u001b[0m         response_format\u001b[38;5;241m=\u001b[39mresponse_format,\n\u001b[1;32m    154\u001b[0m         chat_completion\u001b[38;5;241m=\u001b[39mraw_completion,\n\u001b[1;32m    155\u001b[0m         input_tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[1;32m    156\u001b[0m     )\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/data_science/lib/python3.10/site-packages/openai/_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1241\u001b[0m     )\n\u001b[0;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/data_science/lib/python3.10/site-packages/openai/_base_client.py:919\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 919\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/data_science/lib/python3.10/site-packages/openai/_base_client.py:1008\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1007\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/miniconda3/envs/data_science/lib/python3.10/site-packages/openai/_base_client.py:1057\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/data_science/lib/python3.10/site-packages/openai/_base_client.py:1008\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1007\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/miniconda3/envs/data_science/lib/python3.10/site-packages/openai/_base_client.py:1057\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/data_science/lib/python3.10/site-packages/openai/_base_client.py:1023\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1022\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1026\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1027\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1031\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1032\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "class Recommendation(BaseModel):\n",
    "    stream: str = Field(description=\"The class the student is in\")\n",
    "    name: str = Field(description=\"The student's name\")\n",
    "    subject: str = Field(description=\"The subject\")\n",
    "    subject_strand: str = Field(description=\"The specific topic within the subject\")\n",
    "    grade_numeric: float = Field(description=\"The grade bound between 1 and 5\")\n",
    "    percentile: float = Field(description=\"Percentile of student\")\n",
    "    strength_or_weakness: str = Field(\n",
    "        description=\"Describe if the student is strong or weak relative to class, use percentile\"\n",
    "    )\n",
    "    recommendations: str = Field(\n",
    "        description=\"A generic recommendation on what they should do. Maybe focus on another strand within the subject or focus on another subject altogether\"\n",
    "    )\n",
    "\n",
    "\n",
    "class RecommendationList(BaseModel):\n",
    "    recommendations: List[Recommendation]\n",
    "\n",
    "\n",
    "model = \"gpt-4o-mini-2024-07-18\"\n",
    "model_kwargs = {\"response_format\": {\"type\": \"json_schema\"}}\n",
    "\n",
    "# model = \"gpt-3.5-turbo\"\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\")\n",
    "llm = ChatOpenAI(model=model, model_kwargs=model_kwargs)\n",
    "# llm_with_structured_output = llm.with_structured_output(RecommendationList)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"\"\"\n",
    "        You are an AI assistant helping me categorize the strenghts and weaknesses of each student relative to their stream.\n",
    "        \n",
    "        The grade numeric is from 1 to 5.\n",
    "\n",
    "        The percentile is there too.\n",
    "\n",
    "        In case a student name who does not exist is input, return a general response.\n",
    "        \n",
    "        Focus on giving your response per student basis.\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=f\"\"\"\n",
    "        Here is some tabular data:\\n{subject_strand_percentile_df.to_string()}\n",
    "        \n",
    "        Can you summarize it?\n",
    "        \n",
    "        Give me a list of json objects looking lke the followng\n",
    "        \n",
    "        {{\n",
    "            \"recommendations\": [\n",
    "                {{\n",
    "                    \"stream\": \"Science\",\n",
    "                    \"name\": \"Alice\",\n",
    "                    \"subject\": \"Math\",\n",
    "                    \"subject_strand\": \"Algebra\",\n",
    "                    \"grade_numeric\": 4.5,\n",
    "                    \"percentile\": 85,\n",
    "                    \"strength_or_weakness\": \"Strong\",\n",
    "                    \"recommendations\": \"Continue with advanced topics.\"\n",
    "                }}\n",
    "            ]\n",
    "        }}\n",
    "\n",
    "        \"\"\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "output = llm.invoke(messages)\n",
    "# output = llm_with_structured_output.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Sure! Here's a summarized classification of the students' strengths and \"\n",
      " 'weaknesses based on their grades and percentiles across different subjects.\\n'\n",
      " '\\n'\n",
      " '### Stream Yellow:\\n'\n",
      " '\\n'\n",
      " '#### Strengths:\\n'\n",
      " '- **Holly**: Strong performance in Spanish Vocabulary (4.7, 87.0) and '\n",
      " 'Geography Human Geography (5.0, 86.1).\\n'\n",
      " '- **Jon**: Excellent in Spanish Vocabulary (5.0, 94.4) and Physics '\n",
      " 'Thermodynamics (5.0, 92.6).\\n'\n",
      " '- **Matthew**: Best performance in Spanish Grammar (4.2, 66.7).\\n'\n",
      " '- **Johnny**: Strong in Math Geometry (4.7, 77.8) and good in Geography '\n",
      " 'Physical Geography (4.0, 76.9).\\n'\n",
      " '- **Emily**: History Ancient History and Medieval History (4.0, 61.1 and '\n",
      " '4.0, 68.5).\\n'\n",
      " '- **Rita**: Strong in Math Algebra (4.7, 81.5).\\n'\n",
      " '- **Virginia**: Geography Human Geography (3.7, 64.8) and good performance '\n",
      " 'in some subjects.\\n'\n",
      " '- **Sarah**: Strong in History Ancient History and Medieval History (4.0, '\n",
      " '61.1 and 4.0, 68.5).\\n'\n",
      " '- **Jennifer**: Good in Geography Human Geography (4.7, 70.4).\\n'\n",
      " '- **Megan**: Strong in English Reading and History Ancient History (4.7, '\n",
      " '90.7).\\n'\n",
      " '- **Molly**: Strong in Geography Physical Geography (5.0, 94.4).\\n'\n",
      " '  \\n'\n",
      " '#### Weaknesses:\\n'\n",
      " '- **Holly**: Needs improvement in Physics Thermodynamics (3.7, 51.9) and '\n",
      " 'History Ancient History (3.7, 46.3).\\n'\n",
      " '- **Matthew**: Consistently below average across subjects, low in English '\n",
      " 'Reading (2.7, 29.6).\\n'\n",
      " '- **Johnny**: Struggles in Physics (Mechanics, 2.3, 31.5; Thermodynamics, '\n",
      " '2.7, 24.1) and History (Medieval History, 2.7, 27.8).\\n'\n",
      " '- **Linda**: Low performance across subjects, especially in Spanish '\n",
      " 'Vocabulary (2.3, 27.8).\\n'\n",
      " '- **Rita**: Needs improvement in Math Geometry (1.7, 14.8).\\n'\n",
      " '- **Paul**: Low scores in English (1.7) and Physics (2.0, 21.3).\\n'\n",
      " '- **Mario**: Weak across multiple subjects, e.g., English Writing (1.7, '\n",
      " '13.0).\\n'\n",
      " '- **Ryan**: Low scores in multiple subjects with struggles in English and '\n",
      " 'History.\\n'\n",
      " '\\n'\n",
      " '### Stream Blue:\\n'\n",
      " '\\n'\n",
      " '#### Strengths:\\n'\n",
      " '- **Megan**: Strong in English (Reading 4.7, 90.7) and History (Ancient 4.7, '\n",
      " '90.7).\\n'\n",
      " '- **Sandra**: Good performance in Geography Human Geography (4.0, 85.2) and '\n",
      " 'Math Geometry (4.3).\\n'\n",
      " '- **Molly**: Strong in multiple subjects, including Geography (5.0, 94.4).\\n'\n",
      " '- **Mallory**: Solid in Geography (4.3, 87.0) and History Ancient History '\n",
      " '(2.0, 50.0).\\n'\n",
      " '  \\n'\n",
      " '#### Weaknesses:\\n'\n",
      " '- **Jeffrey**: Lower scores especially in English (1.7, 33.3) and Spanish '\n",
      " 'Grammar (1.7, 33.3).\\n'\n",
      " '- **Samantha**: Struggles with English Writing (1.7, 20.4) and History (1.3, '\n",
      " '33.3).\\n'\n",
      " '- **Isaac**: Low performance across subjects, especially in English (1.7, '\n",
      " '33.3).\\n'\n",
      " '- **Ryan**: Weak in English (1.7) and History (1.7).\\n'\n",
      " '- **Amanda**: Consistent weaknesses in English and limited performance in '\n",
      " 'most subjects.\\n'\n",
      " '\\n'\n",
      " '### Overall Insights:\\n'\n",
      " '- Students like Jon and Molly showcase exceptional proficiency in multiple '\n",
      " 'areas, while students such as Matthew and Ryan often show lower performance '\n",
      " 'across various subjects.\\n'\n",
      " '- Critical attention is needed for students consistently scoring below '\n",
      " 'average in foundational subjects like English and Math, while efforts can be '\n",
      " 'made to further enhance the strengths of top-performing students.\\n'\n",
      " '\\n'\n",
      " 'This summary outlines the strengths and weaknesses based on their scores '\n",
      " 'across different subjects, providing a clear view of where each student '\n",
      " 'might need focus or can excel further.')\n"
     ]
    }
   ],
   "source": [
    "pprint(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-do\n",
    "\n",
    "1. Best way to add context to GPT model\n",
    "2. How to rely on an LLM for chatbot\n",
    "3. Ollama for local LLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "1. API work.\n",
    "2. Langchain with Deepseek\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context Load(Other thoughts):\n",
    "- On AI Assistant Open\n",
    "- To eliminate need for RAG and Direct Database Access\n",
    "- To refresh the data, reload the page\n",
    "    - Cheaper than retrieving data on every request to chatbot\n",
    "\n",
    "Langgraph(this is what will be used):\n",
    "- routing can be done (different types of questions to be handled differently)\n",
    "- better control of output\n",
    "\n",
    "Deepseek with Langchain(Langgraph):\n",
    "- `ChatDeepSeek` is the interface between Langchain and Deepseek"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
